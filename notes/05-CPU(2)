1. CPU 향상
클럭:
우선 컴퓨터 부품들은 클럭 신호에 맞춰서 움직이며, CPU는 명령어 사이클이라는 정해진 흐름에 맞춰서 명령어들을 실행한다.
만약 클럭신호가 빠르게 반복하게 된다면 CPU포함 컴퓨터 부품들은 그만큼 빠르게 작동하거니와, 명령어 사이클의 주기도 빨라져, 성능이 일반적으로는 좋아진다.
클럭 속도는 1초에 몇번 클럭이 반복되는 지에 따라서 헤르츠 단위로 측정된다. 예컨대 4.9GHz 라면 1초에 49억번 반복 된다는 것이다. (4.9*10^9)
물론 클럭 속도만을 계속 높인다고 해서 그에 비례하여 CPU가 빨라지는 것이 아니다. 대표적인 문제로는 발열 문제가 있다.

코어와 멀티코어:
CPU 성능을 높이는대에는 CPU의 코어와 스레드 수를 늘리는 방법이 있다.
지금까지 알고 있던 명령어를 실행하는 부품으로 여겨졌던 CPU를 코어라고 생각하고, 이제 CPU는 코어 여러개를 포함하고 가지고 있는 부품으로 넓게 생각하면 된다. 이렇게 코어를 여러개 가지고 있는 CPU를 멀티코어 CPU 혹은 멀티코어 프로세서와 같다.
명령어를 실행하는 부품이 코어 수에 따라 늘어나게 된 것으로, 확실히 멀티코어 CPU가 성능이 훨씬 더 좋다. 하지만 이 또한 무작정 코어수를 늘린다고 하여 CPU의 속도가 비례적으로 증가하는 것이 아니다.
예를 들어보자. 코어수가 늘어나더라도, 처리할 연산을 적절히 분배하지 않으면, 제대로 쓰지 못할 코어가 있을 것이다. 
혹은 코어수가 지나치게 많아도, 적절하게 있는 것보다 이점이 별로 없다는 점도 있다. 요리 2인분을 4명이서 하면 빠르지만, 10명이서 한다고 해도, 4명이서 할때보다, 비례적으로 특별히 더 빠르지 않는 것처럼.

+) Amdahl's Law (암달의 법칙)
컴퓨터 시스템의 일부를 개선할 때 전체적으로 얼마만큼의 최대 성능 향상이 있는지 계산하는 데 사용된다.
이렇게 생각하면 된다. 컴퓨터는 모든 프로그램에 대해서 100% 병렬처리를 못한다.
즉 전체 실행 기간에서, 아무리 코어수가 계속 많아 진다고 하더라도, 병렬이 아닌, 순차 처리를 하는 과정의 실행시간에 있어서는 전혀 줄어들지 않는다.
법칙으로는 이런 식이 나온다.
1/(1-P) +(P/S)  // S는 코어 수, P는 병렬화가 가능한 비율, 1-P는 그 반대, 병렬화가 불가능한 비율이다.
여기에서 코어수 S가 정말 많게 무한대로 극한을 취한다고 치자. 그래도 1 / 1-p 으로 한계가 명확하다.
이렇게 코어수에 따라 비례적으로 성능이 좋아진다는 것이 아니다.

스레드와 멀티스레드:
스레드는 ‘실행 흐름의 단위’이다. 하지만 이제부터는 스레드를 하드웨어적 스레드와 소프트웨어적 스레드로 나뉘어서 더 자세하게 보자.

1) 하드웨어적 스레드:
‘하나의 코어가 동시에 처리하는 명령어 단위’이다. 그동안 하나의 코어는 하나의 명령어를 한번씩 실행하는 CPU를 가정하였었다. 반면에 CPU는 하나의 코어로도 여러개의 명령어를 동시에 실행하게 할 수 있다. 
예를 들어보자. 2코어 4스레드 CPU는 코어수는 2개로, 명령어를 실행하는 부품은 2개이지만, 한번에 4개의 명령어를 처리할 수 있는 CPU를 이야기 한다. 이 경우에는 즉 코어 하나 당 두개의 하드웨어 스레드를 처리한다는 말로 봐도 된다.
이런 식으로 하나의 코어로 여러 명령어를 동시에 처리하는 CPU를 멀티스레드 프로세서, 혹은 멀티스레드 CPU라고도 부른다.
멀티스레드 프로세서를 조금 더 봐보자. 하나의 코어로 여러 명령어를 동시에 처리하게 하려면, 제일 필요한 것은 레지스터이다. 
프로그램 카운터, 스택포인터, 메모리 버퍼 레지스터, 메모리 주소 레지스터와 같이 하나의 명령어를 처리하기 위해 필요한 레지스터들을 여러 개 가지고 있게 하는 것이다.
이렇게 하드웨어 스레드를 통해 하나의 코어임에도 불구하고 여러 명령어를 동시에 처리할 수 있으나, 
프로그램 입장에서 봤을때, 스레드는 마치 한번에 하나의 명령어를 처리하는 CPU와 다름 없다..즉 2코어 4스레드 CPU는 코어가 2개임이고, 하나의 CPU가 4개의 명령어를 한번에 처리 할수 있음에도 불구하고, 프로그램은 CPU가 4개 있는 것처럼 생각한다. 
이 ‘4’를 논리 프로세서라고도 한다.

2) 소프트웨어적 스레드:
‘하나의 프로그램에서 독립적으로 실행되는 단위’ 이다. 하나의 프로그램은 실행되는 과정에서, 메모리의 한 부분만 실행될 수도 있지만 대부분은 아니다. 
예를 들어, 컴퓨터로 글을 쓴다고 치자. 입력받은 내용을 화면에 보여주는 기능과, 입력한 내용이 맞춤법에 맞는지 확인하는 기능, 입력한 내용을 수시로 저장하는 기능,  등 여러 기능을 동시에 실행되기 위해서는 각각의 스레드로 만드는 것이다.


2. 명령어 병렬 처리

명령어 병렬 처리 기법은 CPU를 계속 쉬지 않고 작동시키는 기법이며, 여러가지 망법이 있다.
1) 명령어 파이프라인
우선 하나의 명령어가 처리되는 전체 과정을 비슷한 시간 간격으로 나누어 봐야 한다. 명령어 처리 과정을 클럭 단위로 보면 이렇게 나눌 수 있다.
명령어 인출 -> 명령어 해석 -> 명령어 실행 -> 결과 저장
중요한 것은 이거다. 같은 단계가 겹쳐지지만 않는다면 CPU는 각 단계를 동시에 실행할 수 있다는 것이다. 예를 들어 한 명령어가 해석단계에 있다면 다른 명령어는 인출단계를 할 수 있다는 것이다. 즉 그렇게 시간에 맞춰서 같은 단계에만 겹치지 않게, 명령어 실행 과정을 겹치게 두어서, 수행하는 것이다.
이건 단순히 모든 명령어를 순차적으로 처리하는 것보다는 확실히 효율적이다.
그러나, 특정 상황에서는 성능 향상에 실패하는 경우도 있다. 이러한 상황을 파이프라인 위험이라고 한다. 파이프 라인 위험에는 데이터위험, 제어위험, 구조적위험이 있다.

데이터 위험: 
명령어 간 ‘데이터 의존성’ 에 의하여 발생한다. 모든 명령어를 동시에 처리 할 수는 없다.
어떤 명령어는 이전 명령어를 끝까지 실행해야만 실행되는 경우가 있다.
예를 들어보자.
1: R1 <- R2 + R3  // 2: R4 <-R1+R5   이런 상황에 있다고 치자. 
R4가 제대로 저장되기 위해서는 명령어 1번에서의 R1 결과값이 저장되어야 한다. 하지만 만약 명령어 파이프라인에 따라서, 명령어 1 실행이 끝나기 전에 명령어 2를 인출하면 제대로 작동하지 않게 된다.

제어 위험:
주로 분기 등으로 인한 ‘프로그램 카운터의 갑작스러운 변화’ 에 의해 발생한다. 다시 생각해보자. 프로그램 카운터는 일반적인 상황에서는 다음주소로 갱신되는 것이 맞다. 
하지만 if/while 문을 만나고, 분기에 따라 다른 메모리 주소에 점프하여 프로그램 카운터 갑셍 갑작스러운 변화가 생긴다고 치자.
‘나는 11번지 명령어를 인출하고, 파이프라인에 따라서 다음 클럭 시간에는 12번지 인출과, 다음 클럭시간에는 12번지의 해석과 13번지의 인출을 계획하였으나, 11번지에서 점프하였으므로, 이 계획은 헛수고 된 셈이다.’
이런한 제어 위험을 줄이기 위해 CPU는 분기 예측 기법을 사용한다.

구조적 위험
명령어들을 겹쳐 실행하는 과정에서 서로 다른 명령어가 동시에 ALU, 레지스터 등과 같은 CPU 부품을 사용하려 할때 발생한다.
//의문점: 하드웨어적 스레드의 경우에도 하나의 코어가 한번에 2개의 명령어를 처리하는 1코어 2스레드의 경우라고 치자. 레지스터는 복사되어 한 코어 있을테니 그렇다고 치자. 하지만 ALU는 하나이기에, 마찬가지로 구조적 위험이 존재하는 것이 아닌가?
답: 맞다. 구조적 위험은 여전히 존재한다. 

2) 슈퍼스칼라
파이프라이닝은 단일 파이프라인으로도 구현이 가능하지만, CPU에서는 여러개의 파이프라인을 이용한다. 이처럼 CPU내부에 여러개의 명령어 파이프라인을 포함한 구조를 슈퍼스칼라 라고 한다.
명령어 파이프라인은 마치 공장 생산 라인을 한 개 두는 것과 같다면, 슈퍼스칼라는 여러개 두는 것과 비슷하다.
//의문점: 앞전에 배운 멀티코어와 멀티스레드와는 관련이 있는 것인가..? 
//답: 모두 어느정도에서의 병렬처리를 하는 것이 맞지만, 범위가 다르다. 멀티 스레드는 실행 흐름으로, 멀티 스레드와 멀티코어는 실행 흐름과 실행 장치에서이지만, 파이프 라인과 슈퍼스칼라는 명령어의 기준에서 본 것이다.

3) 비순차적 명령어 처리
OoOE 으도 불린다. 명령어를 순차적으로 실행하지 않는 기법이다. 명령어 파이프라이닝, 슈퍼스칼라 기법은 여러 명령어의 순차적인 처리를 기반으로 한 방법이다.
잘 생각해보자. 만약 파이프라이닝에서의 데이터 문제에서 봤을때, 데이터 의존성이 존재하는 두 명령어에 대해서는 원래 대로라면, 인출에서 저장까지가 다 끝나서야 그 다음 명령어를 인출할 수 있을 것이다. 하지만 비순차적 명령어 처리는 이런것이다. 그때까지의 빈 시간이 있기에 그 시간을 서로 데이터 의존성이 아무것도 없는 명령어들이 채워지는 것이다.
즉 명령어를 순차적으로 하는 것이 아니라, 순서를 바꿔도 무방한 명령어를 먼저 실행하여 명령어 파이프라인이 멈추는 것을 방지하는 기법을 비순차적 명령어 처리라고 한다.

3. CISC, RISC
파이프라이닝은 현대 CPU에 대부분 적용되어 있을 정도로 중요한 기법이다. 그렇다면 명령어가 어떻게 생겨야 파이프라이닝이 가능 한 것일까?
이와 관련하여 CPU의 언어인 ISA와 각기 다른 성격의 ISA를 기반으로 설계된 CISC와 RISC를 보겠다.
우선 봐보자. CPU는 여러 제조사가 있고, 각 제조사들 마다의 CPU가 이해하고 실행한는 명령어들은 절대로 다 똑같이 생기지 않았다.
CPU가 이해할 수 있는 명령어들의 모음을 명령어 집합(ISA) 이라고 한다. 즉 CPU마다 ISA는 다를 수 있다는 것이다. 
예를 들어 인텔의 노트북 속 CPU는 애플의 아이폰 속 CPu과 다른 ISA 이기에 서로의 명령어를 이해 할 수 없다. 마찬가지로 명령어가 달라져 어셈블리어도 달라진다.
ISA가 다르면 서로의 명령어를 이해하지 못할 뿐더러, 제어장치가 명령어를 해석하는 방식, 사용되는 레지스터의 종류와개수, 메모리 관리 방법 등 많은 것이 달라진다.
이때, 앞에서 말한, 명령어 병렬 처리 기법(파이프라인, 슈퍼스카라, 비순차적 명령어처리) 를 사용하기에 유리한 명령어 집합이 있고, 아닌 집합도 있다. 그럼 유리한 ISA는 무엇인가..? 그 이야기를 하기 위해 CISC, RISC를 볼거다.

1) CISC
Complex Instruction Set Computer의 약자로, 복잡한 명령어 집합을 활용하는 CPU 라고 생각 해도 된다.
X86, x86-64 는 대표적인 CISC기반의  ISA이다.
우선 다양하고 강력한 기능의 명령어 집합을 활용하기 위하여, 명령어의 형태와 크기가 다양한 ‘가변 길이 명령어 집합’을 활용한다.
이는 상대적으로 적은 수의 명령어로도 프로그램을 실행 할 수 있다는 것이다. 즉 메모리 공간을 절약 할 수 있다는 장점이 있다.
그러나, 명령어가 매우 복잡하고 다양한 기능을 제공하는 성질 때문에, 명령어의 크기와, 실행되기까지의 시간이 일정하지 않는다. 즉 어떤 경우에는 명령어 하나를 실행하는데 여러 클릭 주기를 필요로 하는 셈이다.
위의 단점으로 인하여, 명령어 파이프라인을 구현하는데 매우 어려워진다. 각 명령어가 수행시간이 길고, 각각 다르기 때문이다. 즉 명령어 파이프라인이 제대로 동작하지 않는다.
또한, CISC가 다양한 명령어를 활용할 수 있다고는 하지만, 사용 빈도가 매우 적다. 자주 쓰는 소수의 명령어만 계속 자주 쓰곤 했다는 통계도 있다.

2) RISC
Reduced Instruction Set Computer 의 약자으로, CISC의 단점을 보완한다. 말 그대로 명령어가 짧고 규격화되어 있으며, 되도록 1클럭 내외로 실행되며, 또한 명령어의 종류가 적다.
규격화를 위하여 RISC는 즉 고정 길이 명령어를 활용한다. 이러한 점 때문에 RISC 명령어 집합은 명령어 파이프라이닝에 최적화되어있다.
반면 메모리 접근을 단순화 및 최소화 하는 대신에, 레지스터를 더욱 많이 이용한다. 일반 적인 경우보다 범용 레지스터 개수도 더 많고, 레지스터를 이용하는 연산과정이 더 많다. 또한 명령어의 개수도 많아진다.

다시 정리해보자. ISA는 CPU의 언어이고, RISC와 CISC는 ISA를 설계하는데에 철학이다.
CISC는 복잡하고 다양한 명령어/ 가변 길이/ 명령어 개수 적음/ 파이프라이닝 어려움/ 여러 클럭
RISC는 단순하고 적은 명령어/ 고정 길이/ 명령어 개수 ㅁ낳음/ 파이프라이닝 유리/ 1클럭 내외
